# Data Wrangling and Analysis - WeRateDogs Twitter Data
_Data Wrangling, Data mining, API, Data Exploration (EDA)_

## Introduction
This project focuses on the data wrangling process and preliminary data analysis of the Twitter account @dog_rates, known as WeRateDogs. WeRateDogs is famous for rating dogs with humorous comments. The primary objective of this project is to gather, assess, and clean the data for future analysis. While this report primarily covers data wrangling, it also includes a brief overview of data exploration (EDA) techniques.

### Gathering the Data
The data for this project was collected from three different sources:

1. **The WeRateDogs Twitter Archive**: This dataset (`archive.csv`) contains basic tweet information for over 2300 tweets from WeRateDogs. It was manually downloaded.

2. **Tweet Image Predictions**: The image prediction data (`image_predictions.tsv`) includes predictions about the dog breed based on the images in the tweets. These predictions were generated by a neural network and were programmatically downloaded from a Udacity-provided link.

3. **Additional Data from Twitter API**: The third dataset (`tweet_json`) contains JSON data for each tweet, including retweet and like counts. This data was extracted programmatically from Twitter's API and stored in a CSV file.

### Data Wrangling
The data wrangling process involved several key steps:

1. **Data Gathering**: Each dataset was loaded into separate dataframes for further processing.

2. **Data Assessment**: Both visual and programmatic methods were used to assess the quality and tidiness of the data. Issues such as missing data, duplicate records, and data types were identified.

3. **Data Cleaning**: Data quality and tidiness issues were addressed through a series of cleaning operations. This included handling missing values, correcting data types, and removing duplicates.

### Data Analysis (EDA)
While the primary focus of this project is data wrangling, some preliminary data analysis (EDA) was conducted to gain insights into the data. This involved simple statistics and visualizations to understand tweet distribution, retweet and favorite counts, and common dog breeds.

### Project Files
The main project code is stored in the `Wrangle_act.ipynb` Jupyter Notebook, which contains detailed steps of data wrangling and initial data analysis.

Additionally, the `wrangle_report.html` document provides a more in-depth overview of the data wrangling process, including issues encountered and the steps taken to resolve them.

The `act_report.html` document summarizes the findings from the preliminary data analysis and provides insights into the WeRateDogs Twitter data.

### Conclusion
Data wrangling is a crucial step in any data analysis project, and this project successfully demonstrated the process of gathering, assessing, and cleaning data from multiple sources. The cleaned data is now ready for more in-depth analysis and visualization to uncover interesting insights about WeRateDogs and its ratings of adorable dogs on Twitter.
